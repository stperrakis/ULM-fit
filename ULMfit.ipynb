{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AgrAxuD7tNlk"
   },
   "source": [
    "# **A Brief Introduction**\n",
    "> Neural Networks are a prominent field within Artificial Intelligence today. They are widely used in various services to address both regression and classification problems. In classification tasks, the goal is to categorize observations into predefined classes. However, training models from scratch can be time-consuming and requires a significant amount of data.\n",
    "\n",
    "To reduce the data requirements and potentially shorten training time, advanced techniques like transfer learning have been developed. ULMfit [[1]](https://arxiv.org/abs/1801.06146) is one such inductive transfer learning method introduced by Jeremy Howard and Sebastian Ruder. This project focuses on building a classification algorithm using pretrained models that are fine-tuned with the ULMfit transfer learning method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dbs2Nkto85Fw"
   },
   "source": [
    "## **Problem Statement**\n",
    "\n",
    "\n",
    "\n",
    "> The given dataset contains Twitter posts from airline customers. The posts are labeled as 'positive', 'neutral', or 'negative', representing three possible classes. The goal of this project is to build a neural network model to classify future customer posts into these original classes. Since the posts in the dataset have ground-truth labels, supervised learning methods will be employed to address this problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lrFueoscrk0P"
   },
   "source": [
    "## **General Knowledge**\n",
    "\n",
    "> Recurrent Neural Networks (RNNs) are a class of neural networks that outperform classic Multilayer Perceptrons (MLPs) and Convolutional Neural Networks (CNNs) in sequence analysis due to their design.\n",
    "\n",
    "### **Multi-Layer Perceptrons (MLPs)**\n",
    "1. Each input is considered independently of past and future inputs.\n",
    "2. They require fixed-size inputs.\n",
    "3. They process the entire sequence as a single input, making it difficult to model the internal ordering of the data.\n",
    "\n",
    "### **Convolutional Neural Networks (CNNs)**\n",
    "1. CNNs are suitable for training on spatially structured data, such as images.\n",
    "2. CNNs learn to derive semantically meaningful data representations by encoding spatial dependencies.\n",
    "\n",
    "> As a result, RNNs, which are designed for processing sequential data, are better suited for analyzing Twitter posts generated by customers. However, instead of using traditional RNNs, which suffer from issues such as exploding or vanishing gradients, this project employs the AWD-LSTM approach, as described in [[2]](https://arxiv.org/abs/1708.02182). This method prevents overfitting and ensures that the training process produces a robust model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NaS9WsiFFNJ-"
   },
   "source": [
    "## **Transfer Learning and ULMfit approach**\n",
    "> **Universal Language Model Fine-tuning for Text Classification**\n",
    "\n",
    ">> ULMfit consists of three stages (as illustrated in the original paper):[[1]](https://arxiv.org/abs/1801.06146)):\n",
    " <img src=\"https://humboldt-wi.github.io/blog/img/seminar/group11_peer_reviews/ulmfit.jpeg\" width=\"70%\" height=\"70%\" />\n",
    "\n",
    ">> The figure above illustrates the stages of the ULMFit model, which include:\n",
    "\n",
    "### 1. General-domain LM Pretraining\n",
    ">>> The ULMFit model utilizes Merityâ€™s Wikitext-103 dataset, a large preprocessed subset of English Wikipedia comprising 28,595 articles and 103 million words. The language model is trained by passing the text corpus through a bidirectional language model with an embedding size of 400, **3 layers**, and 1150 hidden activations per layer. Since this project focuses on transfer learning, we will not train a language model from scratch.\n",
    "\n",
    "### 2. LM Fine-tuning\n",
    ">>> After obtaining the language model, transfer learning methods are applied to adapt it to the target data. In earlier approaches, only a single layer of weights (embeddings) was used for transfer learning, which barely impacted the deeper layers of the neural network. Modern neural networks typically have multiple layers, so the transfer of information across all layers is essential for accurate predictions.\n",
    "\n",
    "### 3. Classifier Fine-tuning\n",
    ">>> Fine-tuning the classifier for the target task is a critical step. Just as the language model is fine-tuned, the classifier must also undergo non-aggressive fine-tuning. Overly aggressive fine-tuning can lead to catastrophic forgetting, while being too cautious may result in slow convergence and potential overfitting of the model.\n",
    "\n",
    "---\n",
    "\n",
    "> According to the article on ULMFit for text classification, it requires the following:\n",
    "\n",
    "### 1. Discriminative Fine-tuning\n",
    ">>> The layers of a neural network capture different types of information. The ULMFit method fine-tunes each layer differently, recognizing their unique contributions.\n",
    "\n",
    "### 2. Slanted Triangular Learning Rates\n",
    ">>> The goal is for the model to quickly converge to an appropriate parameter space early in training and then refine its parameters. Instead of manually setting the learning rates for individual layers, Howard and Ruder introduce **slanted triangular learning rates**. This method linearly increases the learning rate at the beginning and then linearly decreases it.\n",
    "\n",
    "### 3. Gradual Unfreezing\n",
    ">>> Fine-tuning all layers simultaneously is risky and could lead to catastrophic forgetting. To address this, Howard and Ruder propose **gradual unfreezing**. In this approach, the last layer is unfrozen first, and all unfrozen layers are fine-tuned for one epoch. The next lower frozen layer is then unfrozen, and the process is repeated until all layers are fine-tuned, ensuring convergence by the final iteration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W3nJdWngceBp"
   },
   "source": [
    "# **Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ADDivAzSsCl8"
   },
   "source": [
    "\n",
    "## **Import Libraries**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hc79ZuZDehHZ"
   },
   "source": [
    "### **Updates and Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "aM883olMisd1",
    "outputId": "e8c88270-4510-471a-a63a-93ede0e9b868"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<3>WSL (50173) ERROR: CreateProcessCommon:559: execvpe(/bin/bash) failed: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!curl -s https://course.fast.ai/setup/colab | bash #Update the fast.ai version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1BSUp2JVx1K"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fastai'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from fastai.callbacks import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pkaOHCBSe38o"
   },
   "source": [
    "## **Import data.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eUadHMnyium8"
   },
   "outputs": [],
   "source": [
    "from google.colab import * #Mount the folders of Google drive in order to load the data\n",
    "drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1erwrFjFi3jO"
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/data/Tweets.csv') #Reading data from csv\n",
    "tweets.head(5) #Print the 5 first rows of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5-5HijOiq3i"
   },
   "outputs": [],
   "source": [
    "print(tweets.shape) #Shape of the data, so there are 14640 observations, and 15 cattegories of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LC4g9rB6jLbW"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'airline_sentiment':tweets['airline_sentiment'], 'text':tweets['text']}) #Creating a DataFrame. We kept only the Airline sentiment which the label and the text\n",
    "df = df.reset_index(drop = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S1tKIYnvoEBZ"
   },
   "outputs": [],
   "source": [
    "df['airline_sentiment'].value_counts() #Observing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y3KpZAhBjM_w"
   },
   "outputs": [],
   "source": [
    "df.head(5) #Print 5 lines of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "63YUHOYqf8sC"
   },
   "source": [
    "## **Preprocessing Data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3DEyrJJFoMtu"
   },
   "outputs": [],
   "source": [
    "#df['text'] = df['text'].str.replace(\"[^a-zA-Z]\", \" \") #Keep only letters, although emojis can be a individual message\n",
    "#df.head(5) #Preview the data after clean the unstructed text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJHeBgg7geNP"
   },
   "source": [
    "[**Influence of Stop-Words Removal on Sequence Patterns Identification within Comparable Corpora**](https://link.springer.com/chapter/10.1007/978-3-319-01466-1_6)\n",
    "\n",
    "---\n",
    "\n",
    "> **Stopwords** can occupy unnecessary space in our dataset and consume valuable processing time. Additionally, search engines are often programmed to ignore them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3t0RnBgKjOzq"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords') #ntlk package contains stop words that are going to be filtered.\n",
    "stop_words = stopwords.words('english')\n",
    "tokenized_doc = df['text'].apply(lambda x: x.split())\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "detokenized_doc = [] \n",
    "for i in range(len(df)): \n",
    "    t = ' '.join(tokenized_doc[i]) \n",
    "    detokenized_doc.append(t) \n",
    "\n",
    "df['text'] = detokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4nH4RC_jQxN"
   },
   "outputs": [],
   "source": [
    "df_trn, df_val = train_test_split(df, stratify = df['airline_sentiment'], test_size = 0.3, random_state = 12) #Split dataset to train(70%) and valid(30%). There is no prooven rule for the dataset split.\n",
    "print('This is the shape of the training data: ',df_trn.shape)\n",
    "print('This is the shape of the validation data: ',df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aCPGEMAJjZo8"
   },
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.from_df(train_df = df_trn, valid_df = df_val, path = \"\") #Using TextLMDataBunch it automatically does some preprocessing steps.\n",
    "data_clas = TextClasDataBunch.from_df(path = \"\", train_df = df_trn, valid_df = df_val, vocab=data_lm.train_ds.vocab, bs=64)\n",
    "labels = data_clas.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RaEoHdbP6Fka"
   },
   "source": [
    "## **Language Model Training.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LiZ0B-52lcjp"
   },
   "source": [
    "### [**Language Models**](https://en.wikipedia.org/wiki/Language_model)\n",
    "---\n",
    "\n",
    "> **Language modeling** plays a pivotal role in modern NLP applications. It enables machines to interpret and process qualitative information by converting it into quantitative data. This transformation allows humans to communicate with machines in a way that somewhat resembles natural human interaction, albeit within certain limitations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4NoMKtvokRTB"
   },
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3,pretrained=True)#Initilization of the language model.\n",
    "learn.lr_find(start_lr=1e-8, end_lr=1e2)#Find a good learning rate. We need to find an optimal learning rate for a good training and fast covergence. Slanted triangular learning rates. \n",
    "learn.recorder.plot(suggestion=True)#Ploting the graph of the losses in relation with the Learning rates.\n",
    "\n",
    "learning_rate = learn.recorder.min_grad_lr#Store learning rate.\n",
    "learning_rate = learning_rate + learning_rate/2#Slightly increase at the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H2WgpogVx04-"
   },
   "outputs": [],
   "source": [
    "learn.freeze_to(-1)#freeze the weights exept the weights of the last layer\n",
    "learn.fit_one_cycle(10, learning_rate,callbacks=[SaveModelCallback(learn, name=\"best_lm\")],moms=(0.8,0.7)) #Fine-tune the model, Learning rate: learning_rate and finaly save the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gIKS-FqA9INh"
   },
   "outputs": [],
   "source": [
    "learn.load('best_lm') #Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZTVrO140aPN"
   },
   "outputs": [],
   "source": [
    "learn.unfreeze() #Make sure that the weights are adjustable.\n",
    "learn.freeze_to(-2)#freeze the weights exept the weights of the last 2 layers\n",
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)\n",
    "learning_rate = learn.recorder.min_grad_lr\n",
    "learning_rate = learning_rate + learning_rate/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sVxHJgeM5yLf"
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()#Unfreeze the all the weights of all layers\n",
    "learn.fit_one_cycle(10, learning_rate,callbacks=[SaveModelCallback(learn, name=\"best_lm\")],moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Bjuss3h2Q5z"
   },
   "outputs": [],
   "source": [
    "learn.load(\"best_lm\")#Load the best model according the previous training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MMj8Ta4LkkUc"
   },
   "outputs": [],
   "source": [
    "learn.save_encoder('fine_tuned_enc')#Saving the Language Model in order to use it in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xKn_W2_irHiC"
   },
   "source": [
    "## **Initilization and Training of the classifier.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gbDFzZC-roTd"
   },
   "outputs": [],
   "source": [
    "data_clas.show_batch() #Preview the data will be fed in the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_uJkxotVlTwR"
   },
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)#Initialization of the classifier.\n",
    "learn.load_encoder('fine_tuned_enc')#Load the Language Model that we trained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z6F9mqnN98Zg"
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)\n",
    "learning_rate = learn.recorder.min_grad_lr\n",
    "learning_rate = learning_rate + learning_rate/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p_rIwcMWOKzO"
   },
   "outputs": [],
   "source": [
    "learn.freeze_to(-1)#Gradually Unfreezing: Unfreeze the last layer of the classifier \n",
    "learn.fit_one_cycle(1, learning_rate,moms=(0.8,0.7))\n",
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i5N54jKS-VyL"
   },
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)#Gradually Unfreezing: Unfreeze the last 2 layers of the classifier \n",
    "learn.fit_one_cycle(2,learning_rate, moms=(0.8, 0.7))\n",
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zrtnBBDflXGQ"
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()#Unfreeze all the weights of the network\n",
    "learn.lr_find()#Find a possible optimal learning rate\n",
    "learn.recorder.plot(suggestion=True)\n",
    "learning_rate = learn.recorder.min_grad_lr\n",
    "learning_rate = learning_rate + learning_rate/2 #Slightly increase the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E04d9ZXzA3JF"
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(3, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FtISu8rNlq7x"
   },
   "outputs": [],
   "source": [
    "learn.show_results(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jaCO4LaDrc5t"
   },
   "source": [
    "# **Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QGH92Ulw7aLr"
   },
   "outputs": [],
   "source": [
    "pred_clas, pred_idx, out = learn.predict('This flight was not good, I want my money back!')\n",
    "labels[try_int(pred_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ruPDyUrq7i_t"
   },
   "outputs": [],
   "source": [
    "pred_clas, pred_idx, out = learn.predict('Great flight, see you again, I would love to flight again with you!')\n",
    "labels[try_int(pred_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pW3U42MV7qo4"
   },
   "outputs": [],
   "source": [
    "pred_clas,pred_idx,out=learn.predict('Thank you so much <3 love you!')\n",
    "labels[try_int(pred_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3V6R1NSyCLZu"
   },
   "outputs": [],
   "source": [
    "pred_clas,pred_idx,out= learn.predict('NO NO NO')\n",
    "labels[try_int(pred_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qmGMoUUuCTUv"
   },
   "outputs": [],
   "source": [
    "pred_clas,pred_idx,out=learn.predict('I love you!')\n",
    "labels[try_int(pred_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bII_rbt5h3wN"
   },
   "outputs": [],
   "source": [
    "pred_clas,pred_idx,out=learn.predict('I <3 you!')\n",
    "labels[try_int(pred_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dNtOivi7h5KD"
   },
   "outputs": [],
   "source": [
    "pred_clas,pred_idx,out=learn.predict('I hate you!')\n",
    "labels[try_int(pred_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JUHQJP2Xh7Cg"
   },
   "outputs": [],
   "source": [
    "pred_clas,pred_idx,out=learn.predict('Such a bad flight')\n",
    "labels[try_int(pred_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ql6zaONwyClW"
   },
   "outputs": [],
   "source": [
    "pred_clas,pred_idx,out=learn.predict('What does the fox say?')\n",
    "labels[try_int(pred_idx)]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM3c8n92W6FsssrJG4T3W6t",
   "collapsed_sections": [
    "WJHeBgg7geNP"
   ],
   "name": "ULMfit.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "stelis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
