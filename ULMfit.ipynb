{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ULMfit.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "WJHeBgg7geNP"
      ],
      "authorship_tag": "ABX9TyM3c8n92W6FsssrJG4T3W6t"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgrAxuD7tNlk",
        "colab_type": "text"
      },
      "source": [
        "# **A brief introduction**\n",
        "> Neural Networks are a prominent field within Artificial Intelligence today. They are widely used in various services to address both regression and classification problems. In classification tasks, the goal is to categorize observations into predefined classes. However, training models from scratch can be time-consuming and requires a significant amount of data.

To mitigate the need for extensive data and reduce training time, advanced techniques like transfer learning have been developed. One such method is ULMfit[[1]](https://arxiv.org/abs/1801.06146), an inductive transfer learning approach introduced by Jeremy Howard and Sebastian Ruder. This project focuses on implementing a classification algorithm by leveraging pretrained models, fine-tuned using the ULMfit transfer learning method.\n
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dbs2Nkto85Fw",
        "colab_type": "text"
      },
      "source": [
        "## **Problem Statement**\n",
        "\n",
        "\n",
        "\n",
        "> The given dataset contains Twitter posts from airline costumers. The posts are labeled as 'positive', 'neutral' and 'negative'. Therefore there are three possible classes. The current projects aims to build a neural network model for classiffy the future posts of the customers at the original classes. Hence, the posts are have their ground-truth label at this project suprvised learning methods will be used for this problem.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrFueoscrk0P",
        "colab_type": "text"
      },
      "source": [
        "## **General Knowledge**\n",
        "\n",
        "> First of all, Recurrent neural network(RNN) is a class of neural networks that outperform classic Multilayer Perceptron(MLP) and Convolutional Neural Networks(CNN) in sequence analysis due their design.\n",
        "\n",
        "> **Multi-Layer Perceptrons (MLPs)**\n",
        "> 1.   Each input is considered independently of past and future inputs.\n",
        "> 2.   It requires fixed-size inputs.\n",
        "> 3.   It accepts the entire sequence as input; modeling the internal ordering of the data is cumbersome.\n",
        "\n",
        "> **Convolutional Neural Networks (CNNs)**\n",
        "> 1.   CNNs are suitable for training on spatially structured data, e.g.,  images.\n",
        "> 2.   CNNs learn to derive semantically meaningful data representations encoding spatial dependencies.\n",
        "\n",
        "> Therefore, RNNs(which are designed processing sequential data) are more suitable for Tweeter's posts generated by customers. However, instead of using original RNN which encounters problems such as gradient explode. This project is going to use an AWD-LSTM approach which is described in [[2]](https://arxiv.org/abs/1708.02182) and prevents models to overfit and eventually the train will output a robust model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaS9WsiFFNJ-",
        "colab_type": "text"
      },
      "source": [
        "## **Transfer Learning and ULMfit approach**\n",
        "> **Universal Language Model Fine-tuning for Text Classification**\n",
        "\n",
        ">> ULMfit is constitued by three stages(image can be found in the original paper[[1]](https://arxiv.org/abs/1801.06146)):\n",
        " <img src=\"https://humboldt-wi.github.io/blog/img/seminar/group11_peer_reviews/ulmfit.jpeg\" width=\"70%\" height=\"70%\" />\n",
        "\n",
        ">> The figure above describes the stages of the ULMFit model which are: \n",
        "\n",
        ">> 1. General-domain LM pretraining.\n",
        ">>> ULMFit model uses Merityâ€™s Wikitext 103 dataset which is created from a pre-processed large subset of English Wikipedia consisting of 28,595 preprocessed Wikipedia articles and 103 million words. Training the language model has been done by running the text corpus through a bidirectional language model with an embedding size of 400, **3 layers** and 1150 hidden activations per layer. Since this project aims to transfer learning we are not going to train a language model from scratch.\n",
        "\n",
        ">> 2. LM fine-tuning.\n",
        ">>> After acquiring the language model, we will now apply transfer learning methods in order to use it on target data. In the past, used to be a single layer of weights (embeddings). However, these weights only penetrate through the surface of the neural network. In practice, neural networks usually contain more than one layer, so the information has to be transferred to other layers to do accurate predictions.\n",
        "\n",
        ">> 3. Classifier fine-tuning. \n",
        ">>>Fine-tuning the target task classifier is crucial part. As the language model's fine-tune, we also need to fine-tune the classifier with non-aggressive fine-tuning way as it will cause catastrophic forgetting and being too cautious would result in a slow convergence and thus the model it might overfit.\n",
        "\n",
        "\n",
        "\n",
        "> According the article of the ULMfit for text classification it demands:\n",
        "> 1. Discriminative fine-tuning.\n",
        ">> The layers of the neural network are different and each layers captures different information. The article of the ULM-fit is fine-tuning each layer with different way. \n",
        "> 2. Slanted triangular learning rates\n",
        ">> According to the article, We would like the model to quickly converge to a suitable region of the parameter space in the beginning of training and then refine its parameters. Thus, instead of setting the learning rates of the individual layers manually. Howard and Ruder use the slanted triangular learning rates. The slanted triangular learning rates method is firstly linearly increase the learning rate and then linearly decays it. \n",
        "> 3. Gradual unfreezing\n",
        ">>  if we fine-tune all the layers at once, it would be risky and might cause catastrophic forgetting. Hence, Howard and Ruders use the Gradual unfreezing method. According to the ULM-fit method: We first unfreeze the last layer and fine-tune all unfrozen layers for one epoch. We then unfreeze the next lower frozen layer and repeat, until we finetune all layers until convergence at the last iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3nJdWngceBp",
        "colab_type": "text"
      },
      "source": [
        "# **Implementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADDivAzSsCl8",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## **Import Libraries**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc79ZuZDehHZ",
        "colab_type": "text"
      },
      "source": [
        "### **Updates and Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM883olMisd1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e8c88270-4510-471a-a63a-93ede0e9b868"
      },
      "source": [
        "!curl -s https://course.fast.ai/setup/colab | bash #Update the fast.ai version\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating fastai...\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1BSUp2JVx1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "from fastai.callbacks import *\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkaOHCBSe38o",
        "colab_type": "text"
      },
      "source": [
        "## **Import data.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUadHMnyium8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import * #Mount the folders of Google drive in order to load the data\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1erwrFjFi3jO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/data/Tweets.csv') #Reading data from csv\n",
        "tweets.head(5) #Print the 5 first rows of the data."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5-5HijOiq3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tweets.shape) #Shape of the data, so there are 14640 observations, and 15 cattegories of each"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC4g9rB6jLbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame({'airline_sentiment':tweets['airline_sentiment'], 'text':tweets['text']}) #Creating a DataFrame. We kept only the Airline sentiment which the label and the text\n",
        "df = df.reset_index(drop = True)\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1tKIYnvoEBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['airline_sentiment'].value_counts() #Observing the data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3KpZAhBjM_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head(5) #Print 5 lines of the data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63YUHOYqf8sC",
        "colab_type": "text"
      },
      "source": [
        "## **Preprocessing Data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DEyrJJFoMtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df['text'] = df['text'].str.replace(\"[^a-zA-Z]\", \" \") #Keep only letters, although emojis can be a individual message\n",
        "#df.head(5) #Preview the data after clean the unstructed text."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJHeBgg7geNP",
        "colab_type": "text"
      },
      "source": [
        "[**Influence of Stop-Words Removal on Sequence Patterns Identification within Comparable Corpora**](https://https://link.springer.com/chapter/10.1007/978-3-319-01466-1_6)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> **Stopwords** can take up space to our dataset and valuable processing time, also search engines are programmmed to ignore them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t0RnBgKjOzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('stopwords') #ntlk package contains stop words that are going to be filtered.\n",
        "stop_words = stopwords.words('english')\n",
        "tokenized_doc = df['text'].apply(lambda x: x.split())\n",
        "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
        "detokenized_doc = [] \n",
        "for i in range(len(df)): \n",
        "    t = ' '.join(tokenized_doc[i]) \n",
        "    detokenized_doc.append(t) \n",
        "\n",
        "df['text'] = detokenized_doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4nH4RC_jQxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_trn, df_val = train_test_split(df, stratify = df['airline_sentiment'], test_size = 0.3, random_state = 12) #Split dataset to train(70%) and valid(30%). There is no prooven rule for the dataset split.\n",
        "print('This is the shape of the training data: ',df_trn.shape)\n",
        "print('This is the shape of the validation data: ',df_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCPGEMAJjZo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm = TextLMDataBunch.from_df(train_df = df_trn, valid_df = df_val, path = \"\") #Using TextLMDataBunch it automatically does some preprocessing steps.\n",
        "data_clas = TextClasDataBunch.from_df(path = \"\", train_df = df_trn, valid_df = df_val, vocab=data_lm.train_ds.vocab, bs=64)\n",
        "labels = data_clas.classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaEoHdbP6Fka",
        "colab_type": "text"
      },
      "source": [
        "## **Language Model Training.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiZ0B-52lcjp",
        "colab_type": "text"
      },
      "source": [
        "### [**Language Models**](https://en.wikipedia.org/wiki/Language_model)\n",
        "---\n",
        "\n",
        "\n",
        ">  **Language modeling** is crucial in modern NLP applications. It is the reason that machines can understand qualitative information. Each language model type, in one way or another, turns qualitative information into quantitative information. This allows people to communicate with machines as they do with each other to a limited extent.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NoMKtvokRTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3,pretrained=True)#Initilization of the language model.\n",
        "learn.lr_find(start_lr=1e-8, end_lr=1e2)#Find a good learning rate. We need to find an optimal learning rate for a good training and fast covergence. Slanted triangular learning rates. \n",
        "learn.recorder.plot(suggestion=True)#Ploting the graph of the losses in relation with the Learning rates.\n",
        "\n",
        "learning_rate = learn.recorder.min_grad_lr#Store learning rate.\n",
        "learning_rate = learning_rate + learning_rate/2#Slightly increase at the learning rate."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2WgpogVx04-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.freeze_to(-1)#freeze the weights exept the weights of the last layer\n",
        "learn.fit_one_cycle(10, learning_rate,callbacks=[SaveModelCallback(learn, name=\"best_lm\")],moms=(0.8,0.7)) #Fine-tune the model, Learning rate: learning_rate and finaly save the best model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIKS-FqA9INh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.load('best_lm') #Load the best model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZTVrO140aPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.unfreeze() #Make sure that the weights are adjustable.\n",
        "learn.freeze_to(-2)#freeze the weights exept the weights of the last 2 layers\n",
        "learn.lr_find()\n",
        "learn.recorder.plot(suggestion=True)\n",
        "learning_rate = learn.recorder.min_grad_lr\n",
        "learning_rate = learning_rate + learning_rate/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVxHJgeM5yLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.unfreeze()#Unfreeze the all the weights of all layers\n",
        "learn.fit_one_cycle(10, learning_rate,callbacks=[SaveModelCallback(learn, name=\"best_lm\")],moms=(0.8,0.7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bjuss3h2Q5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.load(\"best_lm\")#Load the best model according the previous training."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMj8Ta4LkkUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save_encoder('fine_tuned_enc')#Saving the Language Model in order to use it in the future"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKn_W2_irHiC",
        "colab_type": "text"
      },
      "source": [
        "## **Initilization and Training of the classifier.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbDFzZC-roTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_clas.show_batch() #Preview the data will be fed in the classifier."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uJkxotVlTwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)#Initialization of the classifier.\n",
        "learn.load_encoder('fine_tuned_enc')#Load the Language Model that we trained above."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6F9mqnN98Zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot(suggestion=True)\n",
        "learning_rate = learn.recorder.min_grad_lr\n",
        "learning_rate = learning_rate + learning_rate/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p_rIwcMWOKzO",
        "colab": {}
      },
      "source": [
        "learn.freeze_to(-1)#Gradually Unfreezing: Unfreeze the last layer of the classifier \n",
        "learn.fit_one_cycle(1, learning_rate,moms=(0.8,0.7))\n",
        "learn.recorder.plot_losses()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5N54jKS-VyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.freeze_to(-2)#Gradually Unfreezing: Unfreeze the last 2 layers of the classifier \n",
        "learn.fit_one_cycle(2,learning_rate, moms=(0.8, 0.7))\n",
        "learn.recorder.plot_losses()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrtnBBDflXGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.unfreeze()#Unfreeze all the weights of the network\n",
        "learn.lr_find()#Find a possible optimal learning rate\n",
        "learn.recorder.plot(suggestion=True)\n",
        "learning_rate = learn.recorder.min_grad_lr\n",
        "learning_rate = learning_rate + learning_rate/2 #Slightly increase the learning rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E04d9ZXzA3JF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(3, learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtISu8rNlq7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.show_results(1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaCO4LaDrc5t",
        "colab_type": "text"
      },
      "source": [
        "# **Inference**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGH92Ulw7aLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_clas, pred_idx, out = learn.predict('This flight was not good, I want my money back!')\n",
        "labels[try_int(pred_idx)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruPDyUrq7i_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_clas, pred_idx, out = learn.predict('Great flight, see you again, I would love to flight again with you!')\n",
        "labels[try_int(pred_idx)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pW3U42MV7qo4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_clas,pred_idx,out=learn.predict('Thank you so much <3 love you!')\n",
        "labels[try_int(pred_idx)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V6R1NSyCLZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_clas,pred_idx,out= learn.predict('NO NO NO')\n",
        "labels[try_int(pred_idx)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmGMoUUuCTUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_clas,pred_idx,out=learn.predict('I love you!')\n",
        "labels[try_int(pred_idx)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bII_rbt5h3wN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_clas,pred_idx,out=learn.predict('I <3 you!')\n",
        "labels[try_int(pred_idx)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNtOivi7h5KD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_clas,pred_idx,out=learn.predict('I hate you!')\n",
        "labels[try_int(pred_idx)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUHQJP2Xh7Cg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_clas,pred_idx,out=learn.predict('Such a bad flight')\n",
        "labels[try_int(pred_idx)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql6zaONwyClW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_clas,pred_idx,out=learn.predict('What does the fox say?')\n",
        "labels[try_int(pred_idx)]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
